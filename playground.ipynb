{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "!pip install git+https://github.com/openai/CLIP.git\n",
    "!wget https://people.eecs.berkeley.edu/~efros/img/Efros__photo_Peter_Badge_crop.jpg\n",
    "!mv Efros__photo_Peter_Badge_crop.jpg efros.jpg"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: imageio in /home/oleksiiv/anaconda3/envs/ganenv4/lib/python3.9/site-packages (2.9.0)\n",
      "Requirement already satisfied: pillow in /home/oleksiiv/anaconda3/envs/ganenv4/lib/python3.9/site-packages (from imageio) (8.3.1)\n",
      "Requirement already satisfied: numpy in /home/oleksiiv/anaconda3/envs/ganenv4/lib/python3.9/site-packages (from imageio) (1.21.2)\n",
      "Requirement already satisfied: imageio-ffmpeg in /home/oleksiiv/anaconda3/envs/ganenv4/lib/python3.9/site-packages (0.4.5)\n",
      "Requirement already satisfied: kmeans-pytorch in /home/oleksiiv/anaconda3/envs/ganenv4/lib/python3.9/site-packages (0.3)\n",
      "--2021-09-16 22:05:08--  https://people.eecs.berkeley.edu/~efros/img/Efros__photo_Peter_Badge_crop.jpg\n",
      "Resolving people.eecs.berkeley.edu (people.eecs.berkeley.edu)... 128.32.244.190\n",
      "Connecting to people.eecs.berkeley.edu (people.eecs.berkeley.edu)|128.32.244.190|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 456031 (445K) [image/jpeg]\n",
      "Saving to: ‘Efros__photo_Peter_Badge_crop.jpg’\n",
      "\n",
      "Efros__photo_Peter_ 100%[===================>] 445.34K  1.75MB/s    in 0.2s    \n",
      "\n",
      "2021-09-16 22:05:08 (1.75 MB/s) - ‘Efros__photo_Peter_Badge_crop.jpg’ saved [456031/456031]\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import annotations"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "source": [
    "import copy\n",
    "import os\n",
    "from time import perf_counter\n",
    "import click\n",
    "import imageio\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import einops\n",
    "\n",
    "import dnnlib\n",
    "import legacy\n",
    "\n",
    "from projector import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# network_pkl = \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\"\n",
    "network_pkl = \"https://nvlabs-fi-cdn.nvidia.com/stylegan2/networks/stylegan2-car-config-f.pkl\"\n",
    "target_fname = \"efros.jpg\"\n",
    "outdir = \"out\"\n",
    "save_video = True\n",
    "seed = 202\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "num_steps = 200\n",
    "device = torch.device('cuda')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "gen = Generator(network_pkl, device=device)\n",
    "latent = gen.sample_latent(10)\n",
    "images = gen.latent_to_image(latent)\n",
    "print(latent.shape, images.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([10, 1, 512]) torch.Size([10, 3, 512, 512])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "gen = Generator(network_pkl, latent_space='w', device=device)\n",
    "prior = Prior(gen, device=device, prior_type='l2', regularize_w_l2=0.05)\n",
    "\n",
    "blue_target = torch.cat((torch.zeros(2, 512, 512), 255*torch.ones(1, 512, 512)), 0)\n",
    "task = Task(device=device, target=blue_target)\n",
    "projector = Projector(gen, task, prior=prior, device=device)\n",
    "\n",
    "# Optimize projection.\n",
    "start_time = perf_counter()\n",
    "\n",
    "# later TODO mem optimization -> mixed precision, gradient checkpointing, multiGPU \n",
    "projected_w_steps = projector.project(\n",
    "    num_images=6,\n",
    "    num_steps=100,\n",
    ")\n",
    "\n",
    "print (f'Elapsed: {(perf_counter()-start_time):.1f} s')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Computing W midpoint and stddev using 10000 samples...\n",
      "step    1/100: loss 28893.53\n",
      "step    2/100: loss 27314.04\n",
      "step    3/100: loss 23346.91\n",
      "step    4/100: loss 17142.20\n",
      "step    5/100: loss 11136.33\n",
      "step    6/100: loss 7090.74\n",
      "step    7/100: loss 6215.59\n",
      "step    8/100: loss 6988.26\n",
      "step    9/100: loss 8380.51\n",
      "step   10/100: loss 9475.97\n",
      "step   11/100: loss 9707.96\n",
      "step   12/100: loss 9009.28\n",
      "step   13/100: loss 7402.72\n",
      "step   14/100: loss 5434.17\n",
      "step   15/100: loss 3617.15\n",
      "step   16/100: loss 2286.16\n",
      "step   17/100: loss 1649.32\n",
      "step   18/100: loss 1473.41\n",
      "step   19/100: loss 1535.36\n",
      "step   20/100: loss 1764.03\n",
      "step   21/100: loss 2015.69\n",
      "step   22/100: loss 2162.27\n",
      "step   23/100: loss 2190.57\n",
      "step   24/100: loss 2100.80\n",
      "step   25/100: loss 1930.65\n",
      "step   26/100: loss 1729.09\n",
      "step   27/100: loss 1484.46\n",
      "step   28/100: loss 1168.09\n",
      "step   29/100: loss 822.96\n",
      "step   30/100: loss 527.54\n",
      "step   31/100: loss 330.16\n",
      "step   32/100: loss 245.18\n",
      "step   33/100: loss 267.82\n",
      "step   34/100: loss 358.57\n",
      "step   35/100: loss 465.39\n",
      "step   36/100: loss 529.04\n",
      "step   37/100: loss 525.72\n",
      "step   38/100: loss 480.24\n",
      "step   39/100: loss 416.76\n",
      "step   40/100: loss 360.67\n",
      "step   41/100: loss 305.03\n",
      "step   42/100: loss 237.55\n",
      "step   43/100: loss 184.19\n",
      "step   44/100: loss 154.07\n",
      "step   45/100: loss 146.69\n",
      "step   46/100: loss 159.21\n",
      "step   47/100: loss 177.04\n",
      "step   48/100: loss 188.97\n",
      "step   49/100: loss 186.46\n",
      "step   50/100: loss 167.66\n",
      "step   51/100: loss 138.97\n",
      "step   52/100: loss 110.65\n",
      "step   53/100: loss 85.01\n",
      "step   54/100: loss 65.18\n",
      "step   55/100: loss 48.16\n",
      "step   56/100: loss 36.82\n",
      "step   57/100: loss 33.66\n",
      "step   58/100: loss 30.40\n",
      "step   59/100: loss 30.38\n",
      "step   60/100: loss 33.39\n",
      "step   61/100: loss 37.25\n",
      "step   62/100: loss 41.14\n",
      "step   63/100: loss 41.59\n",
      "step   64/100: loss 39.64\n",
      "step   65/100: loss 38.51\n",
      "step   66/100: loss 37.32\n",
      "step   67/100: loss 36.32\n",
      "step   68/100: loss 33.15\n",
      "step   69/100: loss 24.19\n",
      "step   70/100: loss 15.69\n",
      "step   71/100: loss 15.62\n",
      "step   72/100: loss 17.30\n",
      "step   73/100: loss 15.11\n",
      "step   74/100: loss 16.89\n",
      "step   75/100: loss 19.57\n",
      "step   76/100: loss 16.14\n",
      "step   77/100: loss 13.52\n",
      "step   78/100: loss 12.89\n",
      "step   79/100: loss 9.23 \n",
      "step   80/100: loss 7.24 \n",
      "step   81/100: loss 8.03 \n",
      "step   82/100: loss 6.67 \n",
      "step   83/100: loss 6.99 \n",
      "step   84/100: loss 7.67 \n",
      "step   85/100: loss 7.42 \n",
      "step   86/100: loss 8.05 \n",
      "step   87/100: loss 7.51 \n",
      "step   88/100: loss 7.64 \n",
      "step   89/100: loss 7.07 \n",
      "step   90/100: loss 6.83 \n",
      "step   91/100: loss 6.55 \n",
      "step   92/100: loss 6.06 \n",
      "step   93/100: loss 5.95 \n",
      "step   94/100: loss 5.79 \n",
      "step   95/100: loss 5.58 \n",
      "step   96/100: loss 5.48 \n",
      "step   97/100: loss 5.43 \n",
      "step   98/100: loss 5.40 \n",
      "step   99/100: loss 5.38 \n",
      "step  100/100: loss 5.36 \n",
      "Elapsed: 32.9 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "source": [
    "print(projected_w_steps.shape)\n",
    "print(projected_w_steps[0,2,0] == projected_w_steps[0,2,1])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([100, 6, 16, 512])\n",
      "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
      "        True, True, True, True, True, True, True, True], device='cuda:0')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "gen = Generator(network_pkl, device=device)\n",
    "prior = Prior(gen, device=device, prior_type='cluster', regularize_cluster_weight=0.05)\n",
    "\n",
    "blue_target = torch.cat((torch.zeros(2, 512, 512), 255*torch.ones(1, 512, 512)), 0)\n",
    "task = Task(device=device, target=blue_target)\n",
    "projector = Projector(gen, task, prior=prior, device=device)\n",
    "\n",
    "# Optimize projection.\n",
    "start_time = perf_counter()\n",
    "\n",
    "# later TODO mem optimization -> mixed precision, gradient checkpointing, multiGPU \n",
    "projected_w_steps = projector.project(\n",
    "    num_images=6,\n",
    "    num_steps=100,\n",
    ")\n",
    "\n",
    "print (f'Elapsed: {(perf_counter()-start_time):.1f} s')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Computing W midpoint and stddev using 10000 samples...\n",
      "step    1/100: loss 19501.38\n",
      "step    2/100: loss 13564.70\n",
      "step    3/100: loss 11392.08\n",
      "step    4/100: loss 8324.23\n",
      "step    5/100: loss 6648.95\n",
      "step    6/100: loss 5437.71\n",
      "step    7/100: loss 4410.93\n",
      "step    8/100: loss 3269.49\n",
      "step    9/100: loss 2947.05\n",
      "step   10/100: loss 3288.89\n",
      "step   11/100: loss 3944.55\n",
      "step   12/100: loss 4612.66\n",
      "step   13/100: loss 4648.57\n",
      "step   14/100: loss 4356.61\n",
      "step   15/100: loss 3885.59\n",
      "step   16/100: loss 3181.38\n",
      "step   17/100: loss 2515.08\n",
      "step   18/100: loss 1891.19\n",
      "step   19/100: loss 1254.38\n",
      "step   20/100: loss 838.05\n",
      "step   21/100: loss 633.57\n",
      "step   22/100: loss 556.24\n",
      "step   23/100: loss 560.92\n",
      "step   24/100: loss 540.19\n",
      "step   25/100: loss 457.61\n",
      "step   26/100: loss 342.23\n",
      "step   27/100: loss 230.10\n",
      "step   28/100: loss 172.67\n",
      "step   29/100: loss 183.60\n",
      "step   30/100: loss 223.20\n",
      "step   31/100: loss 240.28\n",
      "step   32/100: loss 254.94\n",
      "step   33/100: loss 253.92\n",
      "step   34/100: loss 208.81\n",
      "step   35/100: loss 141.69\n",
      "step   36/100: loss 81.37\n",
      "step   37/100: loss 62.82\n",
      "step   38/100: loss 77.93\n",
      "step   39/100: loss 91.30\n",
      "step   40/100: loss 101.96\n",
      "step   41/100: loss 101.40\n",
      "step   42/100: loss 99.33\n",
      "step   43/100: loss 97.68\n",
      "step   44/100: loss 83.21\n",
      "step   45/100: loss 65.52\n",
      "step   46/100: loss 55.33\n",
      "step   47/100: loss 46.55\n",
      "step   48/100: loss 40.15\n",
      "step   49/100: loss 42.41\n",
      "step   50/100: loss 46.32\n",
      "step   51/100: loss 45.27\n",
      "step   52/100: loss 32.58\n",
      "step   53/100: loss 19.15\n",
      "step   54/100: loss 16.39\n",
      "step   55/100: loss 18.89\n",
      "step   56/100: loss 23.29\n",
      "step   57/100: loss 23.56\n",
      "step   58/100: loss 22.31\n",
      "step   59/100: loss 23.21\n",
      "step   60/100: loss 21.54\n",
      "step   61/100: loss 19.29\n",
      "step   62/100: loss 18.30\n",
      "step   63/100: loss 16.90\n",
      "step   64/100: loss 13.84\n",
      "step   65/100: loss 10.22\n",
      "step   66/100: loss 11.73\n",
      "step   67/100: loss 14.66\n",
      "step   68/100: loss 12.39\n",
      "step   69/100: loss 9.28 \n",
      "step   70/100: loss 9.58 \n",
      "step   71/100: loss 11.53\n",
      "step   72/100: loss 11.86\n",
      "step   73/100: loss 12.33\n",
      "step   74/100: loss 12.03\n",
      "step   75/100: loss 9.23 \n",
      "step   76/100: loss 8.54 \n",
      "step   77/100: loss 9.70 \n",
      "step   78/100: loss 8.23 \n",
      "step   79/100: loss 5.74 \n",
      "step   80/100: loss 6.49 \n",
      "step   81/100: loss 7.35 \n",
      "step   82/100: loss 5.74 \n",
      "step   83/100: loss 6.24 \n",
      "step   84/100: loss 6.74 \n",
      "step   85/100: loss 5.62 \n",
      "step   86/100: loss 6.11 \n",
      "step   87/100: loss 5.14 \n",
      "step   88/100: loss 5.36 \n",
      "step   89/100: loss 4.84 \n",
      "step   90/100: loss 5.14 \n",
      "step   91/100: loss 4.87 \n",
      "step   92/100: loss 4.92 \n",
      "step   93/100: loss 4.93 \n",
      "step   94/100: loss 4.75 \n",
      "step   95/100: loss 4.70 \n",
      "step   96/100: loss 4.70 \n",
      "step   97/100: loss 4.67 \n",
      "step   98/100: loss 4.62 \n",
      "step   99/100: loss 4.59 \n",
      "step  100/100: loss 4.58 \n",
      "Elapsed: 34.3 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "gen = Generator(network_pkl, device=device)\n",
    "task = Task(device=device, task_type = 'clip_text', target_str = 'racecar')\n",
    "prior = Prior(gen, device=device, prior_type='cluster', regularize_cluster_weight=0.01)\n",
    "projector = Projector(gen, task, prior=prior, device=device)\n",
    "\n",
    "# Optimize projection.\n",
    "start_time = perf_counter()\n",
    "\n",
    "# later TODO mem optimization -> mixed precision, gradient checkpointing, multiGPU \n",
    "projected_w_steps = projector.project(\n",
    "    num_images=12,\n",
    "    num_steps=200,\n",
    ")\n",
    "\n",
    "print (f'Elapsed: {(perf_counter()-start_time):.1f} s')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[running kmeans]: 99it [00:14,  6.80it/s, center_shift=0.000000, iteration=99, tol=0.000100]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Computing W midpoint and stddev using 10000 samples...\n",
      "step    1/200: loss 37790.60\n",
      "step    2/200: loss 36154.43\n",
      "step    3/200: loss 34212.82\n",
      "step    4/200: loss 30604.17\n",
      "step    5/200: loss 25753.32\n",
      "step    6/200: loss 20279.76\n",
      "step    7/200: loss 14668.55\n",
      "step    8/200: loss 9365.54\n",
      "step    9/200: loss 5350.07\n",
      "step   10/200: loss 3475.14\n",
      "step   11/200: loss 4059.57\n",
      "step   12/200: loss 6345.83\n",
      "step   13/200: loss 9018.62\n",
      "step   14/200: loss 10828.66\n",
      "step   15/200: loss 11665.45\n",
      "step   16/200: loss 11423.28\n",
      "step   17/200: loss 10243.14\n",
      "step   18/200: loss 8322.96\n",
      "step   19/200: loss 6169.29\n",
      "step   20/200: loss 4194.33\n",
      "step   21/200: loss 2706.40\n",
      "step   22/200: loss 1740.33\n",
      "step   23/200: loss 1287.90\n",
      "step   24/200: loss 1293.53\n",
      "step   25/200: loss 1628.72\n",
      "step   26/200: loss 2115.52\n",
      "step   27/200: loss 2539.29\n",
      "step   28/200: loss 2775.60\n",
      "step   29/200: loss 2784.66\n",
      "step   30/200: loss 2600.95\n",
      "step   31/200: loss 2299.41\n",
      "step   32/200: loss 1953.39\n",
      "step   33/200: loss 1618.75\n",
      "step   34/200: loss 1322.77\n",
      "step   35/200: loss 1073.14\n",
      "step   36/200: loss 881.54\n",
      "step   37/200: loss 742.87\n",
      "step   38/200: loss 653.27\n",
      "step   39/200: loss 595.15\n",
      "step   40/200: loss 552.27\n",
      "step   41/200: loss 516.59\n",
      "step   42/200: loss 493.35\n",
      "step   43/200: loss 475.39\n",
      "step   44/200: loss 454.58\n",
      "step   45/200: loss 419.11\n",
      "step   46/200: loss 377.35\n",
      "step   47/200: loss 346.27\n",
      "step   48/200: loss 326.70\n",
      "step   49/200: loss 315.25\n",
      "step   50/200: loss 298.25\n",
      "step   51/200: loss 281.27\n",
      "step   52/200: loss 263.50\n",
      "step   53/200: loss 240.04\n",
      "step   54/200: loss 202.16\n",
      "step   55/200: loss 152.94\n",
      "step   56/200: loss 107.81\n",
      "step   57/200: loss 78.47\n",
      "step   58/200: loss 63.98\n",
      "step   59/200: loss 60.98\n",
      "step   60/200: loss 67.61\n",
      "step   61/200: loss 83.75\n",
      "step   62/200: loss 102.11\n",
      "step   63/200: loss 112.46\n",
      "step   64/200: loss 110.84\n",
      "step   65/200: loss 99.35\n",
      "step   66/200: loss 82.92\n",
      "step   67/200: loss 63.34\n",
      "step   68/200: loss 43.38\n",
      "step   69/200: loss 27.24\n",
      "step   70/200: loss 19.35\n",
      "step   71/200: loss 19.35\n",
      "step   72/200: loss 23.31\n",
      "step   73/200: loss 27.71\n",
      "step   74/200: loss 33.26\n",
      "step   75/200: loss 40.23\n",
      "step   76/200: loss 44.52\n",
      "step   77/200: loss 43.31\n",
      "step   78/200: loss 38.39\n",
      "step   79/200: loss 34.00\n",
      "step   80/200: loss 28.56\n",
      "step   81/200: loss 19.03\n",
      "step   82/200: loss 11.56\n",
      "step   83/200: loss 12.75\n",
      "step   84/200: loss 16.95\n",
      "step   85/200: loss 17.26\n",
      "step   86/200: loss 17.18\n",
      "step   87/200: loss 20.69\n",
      "step   88/200: loss 22.56\n",
      "step   89/200: loss 20.11\n",
      "step   90/200: loss 17.84\n",
      "step   91/200: loss 16.46\n",
      "step   92/200: loss 13.61\n",
      "step   93/200: loss 11.32\n",
      "step   94/200: loss 11.71\n",
      "step   95/200: loss 12.08\n",
      "step   96/200: loss 11.73\n",
      "step   97/200: loss 13.11\n",
      "step   98/200: loss 15.60\n",
      "step   99/200: loss 16.04\n",
      "step  100/200: loss 14.22\n",
      "step  101/200: loss 12.88\n",
      "step  102/200: loss 14.32\n",
      "step  103/200: loss 18.31\n",
      "step  104/200: loss 21.83\n",
      "step  105/200: loss 19.55\n",
      "step  106/200: loss 12.41\n",
      "step  107/200: loss 10.76\n",
      "step  108/200: loss 15.68\n",
      "step  109/200: loss 16.96\n",
      "step  110/200: loss 12.84\n",
      "step  111/200: loss 13.45\n",
      "step  112/200: loss 20.48\n",
      "step  113/200: loss 25.80\n",
      "step  114/200: loss 27.74\n",
      "step  115/200: loss 27.57\n",
      "step  116/200: loss 22.23\n",
      "step  117/200: loss 14.88\n",
      "step  118/200: loss 15.65\n",
      "step  119/200: loss 19.50\n",
      "step  120/200: loss 15.85\n",
      "step  121/200: loss 11.77\n",
      "step  122/200: loss 14.84\n",
      "step  123/200: loss 15.65\n",
      "step  124/200: loss 11.55\n",
      "step  125/200: loss 12.36\n",
      "step  126/200: loss 15.73\n",
      "step  127/200: loss 14.33\n",
      "step  128/200: loss 14.55\n",
      "step  129/200: loss 19.28\n",
      "step  130/200: loss 20.07\n",
      "step  131/200: loss 16.77\n",
      "step  132/200: loss 15.98\n",
      "step  133/200: loss 16.06\n",
      "step  134/200: loss 14.49\n",
      "step  135/200: loss 14.20\n",
      "step  136/200: loss 14.56\n",
      "step  137/200: loss 14.51\n",
      "step  138/200: loss 17.54\n",
      "step  139/200: loss 22.04\n",
      "step  140/200: loss 21.45\n",
      "step  141/200: loss 15.43\n",
      "step  142/200: loss 11.16\n",
      "step  143/200: loss 12.25\n",
      "step  144/200: loss 14.87\n",
      "step  145/200: loss 14.49\n",
      "step  146/200: loss 11.20\n",
      "step  147/200: loss 9.96 \n",
      "step  148/200: loss 12.21\n",
      "step  149/200: loss 12.94\n",
      "step  150/200: loss 10.17\n",
      "step  151/200: loss 8.86 \n",
      "step  152/200: loss 10.94\n",
      "step  153/200: loss 11.65\n",
      "step  154/200: loss 9.39 \n",
      "step  155/200: loss 8.49 \n",
      "step  156/200: loss 10.06\n",
      "step  157/200: loss 10.22\n",
      "step  158/200: loss 8.67 \n",
      "step  159/200: loss 8.64 \n",
      "step  160/200: loss 9.46 \n",
      "step  161/200: loss 8.83 \n",
      "step  162/200: loss 8.41 \n",
      "step  163/200: loss 8.86 \n",
      "step  164/200: loss 8.55 \n",
      "step  165/200: loss 8.39 \n",
      "step  166/200: loss 8.59 \n",
      "step  167/200: loss 8.30 \n",
      "step  168/200: loss 8.40 \n",
      "step  169/200: loss 8.31 \n",
      "step  170/200: loss 8.26 \n",
      "step  171/200: loss 8.31 \n",
      "step  172/200: loss 8.16 \n",
      "step  173/200: loss 8.27 \n",
      "step  174/200: loss 8.13 \n",
      "step  175/200: loss 8.21 \n",
      "step  176/200: loss 8.11 \n",
      "step  177/200: loss 8.17 \n",
      "step  178/200: loss 8.11 \n",
      "step  179/200: loss 8.11 \n",
      "step  180/200: loss 8.11 \n",
      "step  181/200: loss 8.07 \n",
      "step  182/200: loss 8.11 \n",
      "step  183/200: loss 8.07 \n",
      "step  184/200: loss 8.05 \n",
      "step  185/200: loss 8.07 \n",
      "step  186/200: loss 8.05 \n",
      "step  187/200: loss 8.04 \n",
      "step  188/200: loss 8.05 \n",
      "step  189/200: loss 8.04 \n",
      "step  190/200: loss 8.03 \n",
      "step  191/200: loss 8.03 \n",
      "step  192/200: loss 8.03 \n",
      "step  193/200: loss 8.03 \n",
      "step  194/200: loss 8.03 \n",
      "step  195/200: loss 8.03 \n",
      "step  196/200: loss 8.02 \n",
      "step  197/200: loss 8.02 \n",
      "step  198/200: loss 8.02 \n",
      "step  199/200: loss 8.02 \n",
      "step  200/200: loss 8.02 \n",
      "Elapsed: 112.5 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "# Render debug output: optional video and projected image and W vector.\n",
    "num_rows = 4\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "with torch.no_grad():\n",
    "    if save_video:\n",
    "        video = imageio.get_writer(f'{outdir}/test.mp4', mode='I', fps=10, codec='libx264', bitrate='1M')\n",
    "        print (f'Saving optimization progress video \"{outdir}/test.mp4\"')\n",
    "        for projected_w in projected_w_steps:\n",
    "            synth_image = projector.gen.latent_to_image(projected_w)\n",
    "            synth_image = (synth_image + 1) * (255/2)\n",
    "            synth_image = synth_image.permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8).cpu().numpy()\n",
    "            grid_image = einops.rearrange(synth_image, \"(n1 n2) h w c-> (n1 h) (n2 w) c\", n1=num_rows)\n",
    "            video.append_data(grid_image)\n",
    "            # video.append_data(np.concatenate([target_uint8, synth_image], axis=1))\n",
    "        video.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving optimization progress video \"out/test.mp4\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "[running kmeans]: 58it [00:10,  5.58it/s, center_shift=0.000000, iteration=58, tol=0.000100]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Computing W midpoint and stddev using 10000 samples...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[running kmeans]: 9it [05:51, 39.06s/it, center_shift=2127.009277, iteration=9, tol=0.000100]\n",
      "[running kmeans]: 71it [04:15,  3.60s/it, center_shift=416.422058, iteration=71, tol=0.000100]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step    1/100: loss 24641.39\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step    2/100: loss 23522.60\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step    3/100: loss 19669.75\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step    4/100: loss 13434.20\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step    5/100: loss 8015.63\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step    6/100: loss 5750.13\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step    7/100: loss 6652.37\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step    8/100: loss 8021.27\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step    9/100: loss 8385.34\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   10/100: loss 7734.00\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   11/100: loss 6643.91\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   12/100: loss 5863.29\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   13/100: loss 5372.38\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   14/100: loss 5032.34\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   15/100: loss 4570.23\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   16/100: loss 3886.69\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   17/100: loss 3160.61\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   18/100: loss 2573.24\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   19/100: loss 2259.47\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   20/100: loss 2098.12\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   21/100: loss 1948.55\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   22/100: loss 1688.07\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   23/100: loss 1346.55\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   24/100: loss 1138.47\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   25/100: loss 1137.54\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   26/100: loss 1292.73\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   27/100: loss 1481.16\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   28/100: loss 1506.77\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   29/100: loss 1328.01\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   30/100: loss 1008.00\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   31/100: loss 665.39\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   32/100: loss 420.24\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   33/100: loss 304.05\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   34/100: loss 292.17\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   35/100: loss 326.31\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   36/100: loss 368.80\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   37/100: loss 423.78\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   38/100: loss 469.73\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   39/100: loss 494.48\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   40/100: loss 479.41\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   41/100: loss 407.08\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   42/100: loss 312.44\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   43/100: loss 219.22\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   44/100: loss 147.37\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   45/100: loss 110.95\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   46/100: loss 97.70\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   47/100: loss 98.89\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   48/100: loss 107.97\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   49/100: loss 113.93\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   50/100: loss 119.30\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   51/100: loss 119.00\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   52/100: loss 113.00\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   53/100: loss 105.92\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   54/100: loss 99.48\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   55/100: loss 92.27\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   56/100: loss 80.11\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   57/100: loss 63.51\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   58/100: loss 45.22\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   59/100: loss 30.25\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   60/100: loss 21.13\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   61/100: loss 19.17\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   62/100: loss 23.96\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   63/100: loss 31.64\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   64/100: loss 39.29\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   65/100: loss 43.04\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   66/100: loss 39.36\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   67/100: loss 31.76\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   68/100: loss 25.51\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   69/100: loss 21.41\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   70/100: loss 15.18\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   71/100: loss 9.58 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   72/100: loss 9.42 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   73/100: loss 12.24\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   74/100: loss 13.83\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   75/100: loss 14.46\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   76/100: loss 14.34\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   77/100: loss 12.11\n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   78/100: loss 8.95 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   79/100: loss 8.00 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   80/100: loss 8.00 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   81/100: loss 7.09 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   82/100: loss 6.70 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   83/100: loss 6.87 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   84/100: loss 6.20 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   85/100: loss 6.04 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   86/100: loss 5.54 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   87/100: loss 5.04 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   88/100: loss 4.76 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   89/100: loss 4.46 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   90/100: loss 4.20 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   91/100: loss 4.03 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   92/100: loss 3.73 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   93/100: loss 3.56 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   94/100: loss 3.41 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   95/100: loss 3.25 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   96/100: loss 3.16 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   97/100: loss 3.11 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   98/100: loss 3.07 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step   99/100: loss 3.05 \n",
      "torch.Size([10, 1, 512])\n",
      "torch.Size([6, 10, 1, 512])\n",
      "step  100/100: loss 3.04 \n",
      "Elapsed: 67.8 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save final projected frame and W vector.\n",
    "target_pil.save(f'{outdir}/target.png')\n",
    "projected_w = projected_w_steps[-1]\n",
    "synth_image = G.synthesis(projected_w.unsqueeze(0), noise_mode='const')\n",
    "synth_image = (synth_image + 1) * (255/2)\n",
    "synth_image = synth_image.permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n",
    "PIL.Image.fromarray(synth_image, 'RGB').save(f'{outdir}/projblue.png')\n",
    "np.savez(f'{outdir}/projected_wblue.npz', w=projected_w.unsqueeze(0).cpu().numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([1, 512])\n",
      "Computing W midpoint and stddev using 10000 samples...\n",
      "step    1/100: loss 7803.90\n",
      "step    2/100: loss 9929.82\n",
      "step    3/100: loss 7444.09\n",
      "step    4/100: loss 4298.93\n",
      "step    5/100: loss 2779.84\n",
      "step    6/100: loss 2723.05\n",
      "step    7/100: loss 3702.09\n",
      "step    8/100: loss 4738.89\n",
      "step    9/100: loss 5457.20\n",
      "step   10/100: loss 5363.79\n",
      "step   11/100: loss 4496.58\n",
      "step   12/100: loss 3311.87\n",
      "step   13/100: loss 2301.44\n",
      "step   14/100: loss 1559.28\n",
      "step   15/100: loss 1139.34\n",
      "step   16/100: loss 959.92\n",
      "step   17/100: loss 1137.18\n",
      "step   18/100: loss 1464.91\n",
      "step   19/100: loss 1624.43\n",
      "step   20/100: loss 1567.80\n",
      "step   21/100: loss 1293.72\n",
      "step   22/100: loss 914.23\n",
      "step   23/100: loss 657.61\n",
      "step   24/100: loss 563.56\n",
      "step   25/100: loss 528.72\n",
      "step   26/100: loss 485.11\n",
      "step   27/100: loss 472.07\n",
      "step   28/100: loss 468.77\n",
      "step   29/100: loss 487.82\n",
      "step   30/100: loss 499.33\n",
      "step   31/100: loss 453.42\n",
      "step   32/100: loss 373.87\n",
      "step   33/100: loss 274.30\n",
      "step   34/100: loss 192.45\n",
      "step   35/100: loss 159.56\n",
      "step   36/100: loss 158.88\n",
      "step   37/100: loss 171.45\n",
      "step   38/100: loss 190.64\n",
      "step   39/100: loss 206.20\n",
      "step   40/100: loss 191.54\n",
      "step   41/100: loss 160.69\n",
      "step   42/100: loss 130.08\n",
      "step   43/100: loss 96.94\n",
      "step   44/100: loss 79.06\n",
      "step   45/100: loss 69.20\n",
      "step   46/100: loss 60.18\n",
      "step   47/100: loss 54.65\n",
      "step   48/100: loss 51.35\n",
      "step   49/100: loss 59.30\n",
      "step   50/100: loss 69.80\n",
      "step   51/100: loss 73.11\n",
      "step   52/100: loss 64.45\n",
      "step   53/100: loss 47.65\n",
      "step   54/100: loss 30.95\n",
      "step   55/100: loss 24.24\n",
      "step   56/100: loss 21.87\n",
      "step   57/100: loss 20.96\n",
      "step   58/100: loss 23.62\n",
      "step   59/100: loss 26.92\n",
      "step   60/100: loss 27.91\n",
      "step   61/100: loss 25.47\n",
      "step   62/100: loss 21.11\n",
      "step   63/100: loss 18.10\n",
      "step   64/100: loss 15.60\n",
      "step   65/100: loss 13.21\n",
      "step   66/100: loss 11.82\n",
      "step   67/100: loss 13.72\n",
      "step   68/100: loss 16.70\n",
      "step   69/100: loss 15.74\n",
      "step   70/100: loss 14.44\n",
      "step   71/100: loss 14.41\n",
      "step   72/100: loss 11.94\n",
      "step   73/100: loss 7.77 \n",
      "step   74/100: loss 6.66 \n",
      "step   75/100: loss 7.76 \n",
      "step   76/100: loss 7.98 \n",
      "step   77/100: loss 8.74 \n",
      "step   78/100: loss 11.24\n",
      "step   79/100: loss 12.23\n",
      "step   80/100: loss 10.66\n",
      "step   81/100: loss 8.39 \n",
      "step   82/100: loss 6.97 \n",
      "step   83/100: loss 6.67 \n",
      "step   84/100: loss 5.80 \n",
      "step   85/100: loss 4.62 \n",
      "step   86/100: loss 5.48 \n",
      "step   87/100: loss 4.65 \n",
      "step   88/100: loss 5.19 \n",
      "step   89/100: loss 4.73 \n",
      "step   90/100: loss 5.14 \n",
      "step   91/100: loss 4.61 \n",
      "step   92/100: loss 4.77 \n",
      "step   93/100: loss 4.59 \n",
      "step   94/100: loss 4.32 \n",
      "step   95/100: loss 4.33 \n",
      "step   96/100: loss 4.32 \n",
      "step   97/100: loss 4.24 \n",
      "step   98/100: loss 4.16 \n",
      "step   99/100: loss 4.13 \n",
      "step  100/100: loss 4.11 \n",
      "Elapsed: 31.4 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"out/projblue_clusterreg5.mp4\")"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}