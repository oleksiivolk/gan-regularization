{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "source": [
    "!pip install git+https://github.com/openai/CLIP.git\n",
    "!wget https://people.eecs.berkeley.edu/~efros/img/Efros__photo_Peter_Badge_crop.jpg\n",
    "!mv Efros__photo_Peter_Badge_crop.jpg efros.jpg"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: imageio in /home/oleksiiv/anaconda3/envs/ganenv4/lib/python3.9/site-packages (2.9.0)\n",
      "Requirement already satisfied: pillow in /home/oleksiiv/anaconda3/envs/ganenv4/lib/python3.9/site-packages (from imageio) (8.3.1)\n",
      "Requirement already satisfied: numpy in /home/oleksiiv/anaconda3/envs/ganenv4/lib/python3.9/site-packages (from imageio) (1.21.2)\n",
      "Requirement already satisfied: imageio-ffmpeg in /home/oleksiiv/anaconda3/envs/ganenv4/lib/python3.9/site-packages (0.4.5)\n",
      "Requirement already satisfied: kmeans-pytorch in /home/oleksiiv/anaconda3/envs/ganenv4/lib/python3.9/site-packages (0.3)\n",
      "--2021-09-16 22:05:08--  https://people.eecs.berkeley.edu/~efros/img/Efros__photo_Peter_Badge_crop.jpg\n",
      "Resolving people.eecs.berkeley.edu (people.eecs.berkeley.edu)... 128.32.244.190\n",
      "Connecting to people.eecs.berkeley.edu (people.eecs.berkeley.edu)|128.32.244.190|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 456031 (445K) [image/jpeg]\n",
      "Saving to: ‘Efros__photo_Peter_Badge_crop.jpg’\n",
      "\n",
      "Efros__photo_Peter_ 100%[===================>] 445.34K  1.75MB/s    in 0.2s    \n",
      "\n",
      "2021-09-16 22:05:08 (1.75 MB/s) - ‘Efros__photo_Peter_Badge_crop.jpg’ saved [456031/456031]\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from __future__ import annotations"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import copy\n",
    "import os\n",
    "from time import perf_counter\n",
    "import click\n",
    "import imageio\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import einops\n",
    "\n",
    "import dnnlib\n",
    "import legacy\n",
    "\n",
    "from projector import *"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# network_pkl = \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\"\n",
    "network_pkl = \"https://nvlabs-fi-cdn.nvidia.com/stylegan2/networks/stylegan2-car-config-f.pkl\"\n",
    "target_fname = \"efros.jpg\"\n",
    "outdir = \"out\"\n",
    "save_video = True\n",
    "seed = 202\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "num_steps = 200\n",
    "device = torch.device('cuda')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "gen = Generator(network_pkl, latent_space='w+', device=device)\n",
    "prior = Prior(gen, device=device, prior_type='l2', regularize_w_l2=0.05)\n",
    "\n",
    "blue_target = torch.cat((torch.zeros(2, 512, 512), 255*torch.ones(1, 512, 512)), 0)\n",
    "task = Task(device=device, target=blue_target)\n",
    "projector = Projector(gen, task, prior=prior, device=device)\n",
    "\n",
    "# Optimize projection.\n",
    "start_time = perf_counter()\n",
    "\n",
    "# later TODO mem optimization -> mixed precision, gradient checkpointing, multiGPU \n",
    "projected_w_steps = projector.project(\n",
    "    num_images=6,\n",
    "    num_steps=100,\n",
    ")\n",
    "\n",
    "print (f'Elapsed: {(perf_counter()-start_time):.1f} s')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/oleksiiv/anaconda3/envs/ganenv8/lib/python3.9/site-packages/torch/nn/modules/module.py:1051: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return forward_call(*input, **kwargs)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done.\n",
      "step    1/100: prior_loss 1669.74 task_loss 4.70 \n",
      "step    2/100: prior_loss 1669.74 task_loss 4.70 \n",
      "step    3/100: prior_loss 1617.49 task_loss 4.69 \n",
      "step    4/100: prior_loss 1518.80 task_loss 4.69 \n",
      "step    5/100: prior_loss 1384.58 task_loss 4.69 \n",
      "step    6/100: prior_loss 1228.99 task_loss 4.68 \n",
      "step    7/100: prior_loss 1066.99 task_loss 4.66 \n",
      "step    8/100: prior_loss 934.77 task_loss 4.67 \n",
      "step    9/100: prior_loss 825.99 task_loss 4.66 \n",
      "step   10/100: prior_loss 735.29 task_loss 4.66 \n",
      "step   11/100: prior_loss 658.44 task_loss 4.67 \n",
      "step   12/100: prior_loss 592.26 task_loss 4.66 \n",
      "step   13/100: prior_loss 534.34 task_loss 4.66 \n",
      "step   14/100: prior_loss 483.01 task_loss 4.66 \n",
      "step   15/100: prior_loss 437.08 task_loss 4.65 \n",
      "step   16/100: prior_loss 395.74 task_loss 4.63 \n",
      "step   17/100: prior_loss 358.43 task_loss 4.60 \n",
      "step   18/100: prior_loss 324.71 task_loss 4.57 \n",
      "step   19/100: prior_loss 294.24 task_loss 4.54 \n",
      "step   20/100: prior_loss 266.70 task_loss 4.51 \n",
      "step   21/100: prior_loss 241.81 task_loss 4.47 \n",
      "step   22/100: prior_loss 219.36 task_loss 4.45 \n",
      "step   23/100: prior_loss 199.10 task_loss 4.41 \n",
      "step   24/100: prior_loss 180.82 task_loss 4.38 \n",
      "step   25/100: prior_loss 164.31 task_loss 4.35 \n",
      "step   26/100: prior_loss 149.36 task_loss 4.32 \n",
      "step   27/100: prior_loss 135.77 task_loss 4.31 \n",
      "step   28/100: prior_loss 123.40 task_loss 4.30 \n",
      "step   29/100: prior_loss 112.12 task_loss 4.29 \n",
      "step   30/100: prior_loss 101.82 task_loss 4.28 \n",
      "step   31/100: prior_loss 92.41 task_loss 4.29 \n",
      "step   32/100: prior_loss 83.82 task_loss 4.29 \n",
      "step   33/100: prior_loss 75.99 task_loss 4.29 \n",
      "step   34/100: prior_loss 68.86 task_loss 4.29 \n",
      "step   35/100: prior_loss 62.41 task_loss 4.29 \n",
      "step   36/100: prior_loss 56.57 task_loss 4.30 \n",
      "step   37/100: prior_loss 51.31 task_loss 4.30 \n",
      "step   38/100: prior_loss 46.57 task_loss 4.30 \n",
      "step   39/100: prior_loss 42.29 task_loss 4.29 \n",
      "step   40/100: prior_loss 38.44 task_loss 4.29 \n",
      "step   41/100: prior_loss 34.95 task_loss 4.29 \n",
      "step   42/100: prior_loss 31.79 task_loss 4.29 \n",
      "step   43/100: prior_loss 28.92 task_loss 4.29 \n",
      "step   44/100: prior_loss 26.30 task_loss 4.29 \n",
      "step   45/100: prior_loss 23.92 task_loss 4.29 \n",
      "step   46/100: prior_loss 21.75 task_loss 4.29 \n",
      "step   47/100: prior_loss 19.78 task_loss 4.29 \n",
      "step   48/100: prior_loss 18.00 task_loss 4.30 \n",
      "step   49/100: prior_loss 16.38 task_loss 4.30 \n",
      "step   50/100: prior_loss 14.92 task_loss 4.30 \n",
      "step   51/100: prior_loss 13.59 task_loss 4.30 \n",
      "step   52/100: prior_loss 12.39 task_loss 4.30 \n",
      "step   53/100: prior_loss 11.29 task_loss 4.29 \n",
      "step   54/100: prior_loss 10.30 task_loss 4.30 \n",
      "step   55/100: prior_loss 9.39  task_loss 4.29 \n",
      "step   56/100: prior_loss 8.55  task_loss 4.31 \n",
      "step   57/100: prior_loss 7.80  task_loss 4.30 \n",
      "step   58/100: prior_loss 7.11  task_loss 4.30 \n",
      "step   59/100: prior_loss 6.48  task_loss 4.29 \n",
      "step   60/100: prior_loss 5.92  task_loss 4.29 \n",
      "step   61/100: prior_loss 5.40  task_loss 4.30 \n",
      "step   62/100: prior_loss 4.94  task_loss 4.29 \n",
      "step   63/100: prior_loss 4.52  task_loss 4.30 \n",
      "step   64/100: prior_loss 4.14  task_loss 4.29 \n",
      "step   65/100: prior_loss 3.79  task_loss 4.29 \n",
      "step   66/100: prior_loss 3.47  task_loss 4.28 \n",
      "step   67/100: prior_loss 3.19  task_loss 4.29 \n",
      "step   68/100: prior_loss 2.92  task_loss 4.29 \n",
      "step   69/100: prior_loss 2.69  task_loss 4.29 \n",
      "step   70/100: prior_loss 2.47  task_loss 4.30 \n",
      "step   71/100: prior_loss 2.27  task_loss 4.29 \n",
      "step   72/100: prior_loss 2.09  task_loss 4.29 \n",
      "step   73/100: prior_loss 1.93  task_loss 4.29 \n",
      "step   74/100: prior_loss 1.78  task_loss 4.29 \n",
      "step   75/100: prior_loss 1.64  task_loss 4.28 \n",
      "step   76/100: prior_loss 1.51  task_loss 4.28 \n",
      "step   77/100: prior_loss 1.39  task_loss 4.28 \n",
      "step   78/100: prior_loss 1.28  task_loss 4.28 \n",
      "step   79/100: prior_loss 1.18  task_loss 4.28 \n",
      "step   80/100: prior_loss 1.09  task_loss 4.29 \n",
      "step   81/100: prior_loss 1.01  task_loss 4.29 \n",
      "step   82/100: prior_loss 0.94  task_loss 4.29 \n",
      "step   83/100: prior_loss 0.87  task_loss 4.29 \n",
      "step   84/100: prior_loss 0.82  task_loss 4.28 \n",
      "step   85/100: prior_loss 0.77  task_loss 4.29 \n",
      "step   86/100: prior_loss 0.72  task_loss 4.29 \n",
      "step   87/100: prior_loss 0.68  task_loss 4.29 \n",
      "step   88/100: prior_loss 0.65  task_loss 4.29 \n",
      "step   89/100: prior_loss 0.62  task_loss 4.29 \n",
      "step   90/100: prior_loss 0.60  task_loss 4.29 \n",
      "step   91/100: prior_loss 0.58  task_loss 4.28 \n",
      "step   92/100: prior_loss 0.56  task_loss 4.29 \n",
      "step   93/100: prior_loss 0.55  task_loss 4.29 \n",
      "step   94/100: prior_loss 0.54  task_loss 4.30 \n",
      "step   95/100: prior_loss 0.53  task_loss 4.29 \n",
      "step   96/100: prior_loss 0.52  task_loss 4.29 \n",
      "step   97/100: prior_loss 0.52  task_loss 4.29 \n",
      "step   98/100: prior_loss 0.52  task_loss 4.29 \n",
      "step   99/100: prior_loss 0.52  task_loss 4.30 \n",
      "step  100/100: prior_loss 0.52  task_loss 4.29 \n",
      "Elapsed: 32.8 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "gen = Generator(network_pkl, latent_space='w+', device=device)\n",
    "prior = Prior(gen, device=device, prior_type='cluster', regularize_cluster_weight=0.01)\n",
    "\n",
    "blue_target = torch.cat((torch.zeros(2, 512, 512), 255*torch.ones(1, 512, 512)), 0)\n",
    "task = Task(device=device, target=blue_target)\n",
    "projector = Projector(gen, task, prior=prior, device=device)\n",
    "\n",
    "# Optimize projection.\n",
    "start_time = perf_counter()\n",
    "\n",
    "# later TODO mem optimization -> mixed precision, gradient checkpointing, multiGPU \n",
    "projected_w_steps = projector.project(\n",
    "    num_images=6,\n",
    "    num_steps=100,\n",
    ")\n",
    "\n",
    "print (f'Elapsed: {(perf_counter()-start_time):.1f} s')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[running kmeans]: 58it [00:59,  1.02s/it, center_shift=0.000000, iteration=58, tol=0.000100]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step    1/100: prior_loss 221.40 task_loss 4.72 \n",
      "step    2/100: prior_loss 221.40 task_loss 4.72 \n",
      "step    3/100: prior_loss 212.69 task_loss 4.69 \n",
      "step    4/100: prior_loss 196.43 task_loss 4.61 \n",
      "step    5/100: prior_loss 174.78 task_loss 4.42 \n",
      "step    6/100: prior_loss 150.44 task_loss 4.26 \n",
      "step    7/100: prior_loss 126.03 task_loss 4.12 \n",
      "step    8/100: prior_loss 106.88 task_loss 4.05 \n",
      "step    9/100: prior_loss 91.67 task_loss 3.96 \n",
      "step   10/100: prior_loss 79.37 task_loss 3.89 \n",
      "step   11/100: prior_loss 69.20 task_loss 3.83 \n",
      "step   12/100: prior_loss 60.64 task_loss 3.79 \n",
      "step   13/100: prior_loss 53.32 task_loss 3.74 \n",
      "step   14/100: prior_loss 46.98 task_loss 3.70 \n",
      "step   15/100: prior_loss 41.44 task_loss 3.66 \n",
      "step   16/100: prior_loss 36.58 task_loss 3.63 \n",
      "step   17/100: prior_loss 32.31 task_loss 3.61 \n",
      "step   18/100: prior_loss 28.57 task_loss 3.58 \n",
      "step   19/100: prior_loss 25.29 task_loss 3.56 \n",
      "step   20/100: prior_loss 22.41 task_loss 3.54 \n",
      "step   21/100: prior_loss 19.89 task_loss 3.53 \n",
      "step   22/100: prior_loss 17.68 task_loss 3.52 \n",
      "step   23/100: prior_loss 15.76 task_loss 3.50 \n",
      "step   24/100: prior_loss 14.07 task_loss 3.49 \n",
      "step   25/100: prior_loss 12.60 task_loss 3.48 \n",
      "step   26/100: prior_loss 11.31 task_loss 3.48 \n",
      "step   27/100: prior_loss 10.18 task_loss 3.46 \n",
      "step   28/100: prior_loss 9.18  task_loss 3.46 \n",
      "step   29/100: prior_loss 8.29  task_loss 3.46 \n",
      "step   30/100: prior_loss 7.49  task_loss 3.45 \n",
      "step   31/100: prior_loss 6.78  task_loss 3.44 \n",
      "step   32/100: prior_loss 6.14  task_loss 3.44 \n",
      "step   33/100: prior_loss 5.57  task_loss 3.43 \n",
      "step   34/100: prior_loss 5.06  task_loss 3.42 \n",
      "step   35/100: prior_loss 4.63  task_loss 3.39 \n",
      "step   36/100: prior_loss 4.25  task_loss 3.37 \n",
      "step   37/100: prior_loss 3.89  task_loss 3.36 \n",
      "step   38/100: prior_loss 3.57  task_loss 3.35 \n",
      "step   39/100: prior_loss 3.28  task_loss 3.34 \n",
      "step   40/100: prior_loss 3.01  task_loss 3.34 \n",
      "step   41/100: prior_loss 2.78  task_loss 3.35 \n",
      "step   42/100: prior_loss 2.57  task_loss 3.34 \n",
      "step   43/100: prior_loss 2.38  task_loss 3.34 \n",
      "step   44/100: prior_loss 2.20  task_loss 3.34 \n",
      "step   45/100: prior_loss 2.04  task_loss 3.35 \n",
      "step   46/100: prior_loss 1.89  task_loss 3.35 \n",
      "step   47/100: prior_loss 1.76  task_loss 3.37 \n",
      "step   48/100: prior_loss 1.65  task_loss 3.36 \n",
      "step   49/100: prior_loss 1.54  task_loss 3.36 \n",
      "step   50/100: prior_loss 1.44  task_loss 3.35 \n",
      "step   51/100: prior_loss 1.35  task_loss 3.36 \n",
      "step   52/100: prior_loss 1.27  task_loss 3.36 \n",
      "step   53/100: prior_loss 1.20  task_loss 3.35 \n",
      "step   54/100: prior_loss 1.13  task_loss 3.36 \n",
      "step   55/100: prior_loss 1.07  task_loss 3.36 \n",
      "step   56/100: prior_loss 1.01  task_loss 3.36 \n",
      "step   57/100: prior_loss 0.96  task_loss 3.37 \n",
      "step   58/100: prior_loss 0.91  task_loss 3.35 \n",
      "step   59/100: prior_loss 0.88  task_loss 3.36 \n",
      "step   60/100: prior_loss 0.84  task_loss 3.35 \n",
      "step   61/100: prior_loss 0.81  task_loss 3.36 \n",
      "step   62/100: prior_loss 0.78  task_loss 3.36 \n",
      "step   63/100: prior_loss 0.76  task_loss 3.35 \n",
      "step   64/100: prior_loss 0.73  task_loss 3.37 \n",
      "step   65/100: prior_loss 0.70  task_loss 3.36 \n",
      "step   66/100: prior_loss 0.67  task_loss 3.38 \n",
      "step   67/100: prior_loss 0.66  task_loss 3.36 \n",
      "step   68/100: prior_loss 0.65  task_loss 3.36 \n",
      "step   69/100: prior_loss 0.63  task_loss 3.36 \n",
      "step   70/100: prior_loss 0.61  task_loss 3.36 \n",
      "step   71/100: prior_loss 0.59  task_loss 3.37 \n",
      "step   72/100: prior_loss 0.58  task_loss 3.36 \n",
      "step   73/100: prior_loss 0.58  task_loss 3.36 \n",
      "step   74/100: prior_loss 0.58  task_loss 3.35 \n",
      "step   75/100: prior_loss 0.56  task_loss 3.36 \n",
      "step   76/100: prior_loss 0.55  task_loss 3.37 \n",
      "step   77/100: prior_loss 0.53  task_loss 3.38 \n",
      "step   78/100: prior_loss 0.55  task_loss 3.36 \n",
      "step   79/100: prior_loss 0.56  task_loss 3.35 \n",
      "step   80/100: prior_loss 0.55  task_loss 3.35 \n",
      "step   81/100: prior_loss 0.53  task_loss 3.37 \n",
      "step   82/100: prior_loss 0.51  task_loss 3.38 \n",
      "step   83/100: prior_loss 0.51  task_loss 3.39 \n",
      "step   84/100: prior_loss 0.52  task_loss 3.35 \n",
      "step   85/100: prior_loss 0.53  task_loss 3.36 \n",
      "step   86/100: prior_loss 0.53  task_loss 3.37 \n",
      "step   87/100: prior_loss 0.52  task_loss 3.36 \n",
      "step   88/100: prior_loss 0.50  task_loss 3.37 \n",
      "step   89/100: prior_loss 0.49  task_loss 3.37 \n",
      "step   90/100: prior_loss 0.48  task_loss 3.38 \n",
      "step   91/100: prior_loss 0.48  task_loss 3.38 \n",
      "step   92/100: prior_loss 0.49  task_loss 3.37 \n",
      "step   93/100: prior_loss 0.49  task_loss 3.36 \n",
      "step   94/100: prior_loss 0.50  task_loss 3.35 \n",
      "step   95/100: prior_loss 0.50  task_loss 3.35 \n",
      "step   96/100: prior_loss 0.50  task_loss 3.35 \n",
      "step   97/100: prior_loss 0.50  task_loss 3.35 \n",
      "step   98/100: prior_loss 0.49  task_loss 3.35 \n",
      "step   99/100: prior_loss 0.49  task_loss 3.35 \n",
      "step  100/100: prior_loss 0.49  task_loss 3.35 \n",
      "Elapsed: 32.3 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "gen = Generator(network_pkl, latent_space='z+', device=device)\n",
    "task = Task(device=device, task_type = 'clip_text', target_str = 'racecar')\n",
    "prior = Prior(gen, device=device, prior_type='cluster', regularize_cluster_weight=1.5, cluster_samples=2000)\n",
    "projector = Projector(gen, task, prior=prior, device=device)\n",
    "\n",
    "# Optimize projection.\n",
    "start_time = perf_counter()\n",
    "\n",
    "# later TODO mem optimization -> mixed precision, gradient checkpointing, multiGPU \n",
    "projected_w_steps = projector.project(\n",
    "    num_images=12,\n",
    "    num_steps=100,\n",
    ")\n",
    "\n",
    "print (f'Elapsed: {(perf_counter()-start_time):.1f} s')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "running k-means on cuda..\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[running kmeans]: 108it [00:21,  5.02it/s, center_shift=0.000000, iteration=108, tol=0.000100]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step    1/100: prior_loss 141760.52 task_loss 9.03 \n",
      "step    2/100: prior_loss 141760.52 task_loss 8.99 \n",
      "step    3/100: prior_loss 137204.35 task_loss 9.02 \n",
      "step    4/100: prior_loss 128445.52 task_loss 8.98 \n",
      "step    5/100: prior_loss 116174.78 task_loss 9.00 \n",
      "step    6/100: prior_loss 101363.99 task_loss 9.05 \n",
      "step    7/100: prior_loss 85179.39 task_loss 9.01 \n",
      "step    8/100: prior_loss 71358.27 task_loss 8.95 \n",
      "step    9/100: prior_loss 59644.76 task_loss 8.92 \n",
      "step   10/100: prior_loss 49784.50 task_loss 8.96 \n",
      "step   11/100: prior_loss 41538.85 task_loss 9.02 \n",
      "step   12/100: prior_loss 34685.85 task_loss 9.00 \n",
      "step   13/100: prior_loss 29021.61 task_loss 9.05 \n",
      "step   14/100: prior_loss 24363.93 task_loss 9.06 \n",
      "step   15/100: prior_loss 20549.63 task_loss 9.02 \n",
      "step   16/100: prior_loss 17436.30 task_loss 9.09 \n",
      "step   17/100: prior_loss 14900.57 task_loss 9.09 \n",
      "step   18/100: prior_loss 12835.36 task_loss 9.05 \n",
      "step   19/100: prior_loss 11151.67 task_loss 9.05 \n",
      "step   20/100: prior_loss 9775.24 task_loss 9.05 \n",
      "step   21/100: prior_loss 8644.41 task_loss 9.05 \n",
      "step   22/100: prior_loss 7707.47 task_loss 8.99 \n",
      "step   23/100: prior_loss 6923.34 task_loss 8.99 \n",
      "step   24/100: prior_loss 6259.17 task_loss 9.02 \n",
      "step   25/100: prior_loss 5689.48 task_loss 8.95 \n",
      "step   26/100: prior_loss 5194.06 task_loss 9.04 \n",
      "step   27/100: prior_loss 4757.06 task_loss 9.01 \n",
      "step   28/100: prior_loss 4366.19 task_loss 9.02 \n",
      "step   29/100: prior_loss 4012.53 task_loss 8.97 \n",
      "step   30/100: prior_loss 3689.80 task_loss 9.06 \n",
      "step   31/100: prior_loss 3393.14 task_loss 9.05 \n",
      "step   32/100: prior_loss 3118.63 task_loss 9.03 \n",
      "step   33/100: prior_loss 2863.78 task_loss 8.98 \n",
      "step   34/100: prior_loss 2626.42 task_loss 8.96 \n",
      "step   35/100: prior_loss 2405.11 task_loss 8.91 \n",
      "step   36/100: prior_loss 2199.00 task_loss 8.93 \n",
      "step   37/100: prior_loss 2007.75 task_loss 8.94 \n",
      "step   38/100: prior_loss 1830.52 task_loss 8.92 \n",
      "step   39/100: prior_loss 1666.21 task_loss 8.94 \n",
      "step   40/100: prior_loss 1514.72 task_loss 8.91 \n",
      "step   41/100: prior_loss 1375.33 task_loss 8.85 \n",
      "step   42/100: prior_loss 1247.06 task_loss 8.88 \n",
      "step   43/100: prior_loss 1129.57 task_loss 8.98 \n",
      "step   44/100: prior_loss 1021.98 task_loss 8.92 \n",
      "step   45/100: prior_loss 923.51 task_loss 8.94 \n",
      "step   46/100: prior_loss 833.72 task_loss 8.92 \n",
      "step   47/100: prior_loss 752.07 task_loss 8.95 \n",
      "step   48/100: prior_loss 678.28 task_loss 8.94 \n",
      "step   49/100: prior_loss 611.75 task_loss 8.95 \n",
      "step   50/100: prior_loss 551.56 task_loss 8.96 \n",
      "step   51/100: prior_loss 497.30 task_loss 8.97 \n",
      "step   52/100: prior_loss 448.40 task_loss 8.95 \n",
      "step   53/100: prior_loss 404.48 task_loss 8.98 \n",
      "step   54/100: prior_loss 364.91 task_loss 8.95 \n",
      "step   55/100: prior_loss 329.24 task_loss 8.96 \n",
      "step   56/100: prior_loss 297.10 task_loss 8.98 \n",
      "step   57/100: prior_loss 268.15 task_loss 8.94 \n",
      "step   58/100: prior_loss 242.10 task_loss 8.88 \n",
      "step   59/100: prior_loss 218.53 task_loss 8.88 \n",
      "step   60/100: prior_loss 197.36 task_loss 8.91 \n",
      "step   61/100: prior_loss 178.27 task_loss 8.90 \n",
      "step   62/100: prior_loss 161.00 task_loss 8.92 \n",
      "step   63/100: prior_loss 145.54 task_loss 9.00 \n",
      "step   64/100: prior_loss 131.79 task_loss 9.00 \n",
      "step   65/100: prior_loss 119.34 task_loss 8.97 \n",
      "step   66/100: prior_loss 108.14 task_loss 8.95 \n",
      "step   67/100: prior_loss 98.01 task_loss 8.97 \n",
      "step   68/100: prior_loss 88.82 task_loss 8.98 \n",
      "step   69/100: prior_loss 80.52 task_loss 8.94 \n",
      "step   70/100: prior_loss 72.92 task_loss 8.90 \n",
      "step   71/100: prior_loss 66.00 task_loss 8.88 \n",
      "step   72/100: prior_loss 59.77 task_loss 8.86 \n",
      "step   73/100: prior_loss 54.23 task_loss 8.85 \n",
      "step   74/100: prior_loss 49.34 task_loss 8.84 \n",
      "step   75/100: prior_loss 44.87 task_loss 8.84 \n",
      "step   76/100: prior_loss 40.66 task_loss 8.84 \n",
      "step   77/100: prior_loss 36.77 task_loss 8.86 \n",
      "step   78/100: prior_loss 33.36 task_loss 8.86 \n",
      "step   79/100: prior_loss 30.36 task_loss 8.80 \n",
      "step   80/100: prior_loss 27.69 task_loss 8.84 \n",
      "step   81/100: prior_loss 25.15 task_loss 8.87 \n",
      "step   82/100: prior_loss 22.86 task_loss 8.84 \n",
      "step   83/100: prior_loss 20.81 task_loss 8.86 \n",
      "step   84/100: prior_loss 18.93 task_loss 8.86 \n",
      "step   85/100: prior_loss 17.29 task_loss 8.88 \n",
      "step   86/100: prior_loss 15.77 task_loss 8.84 \n",
      "step   87/100: prior_loss 14.38 task_loss 8.83 \n",
      "step   88/100: prior_loss 13.20 task_loss 8.80 \n",
      "step   89/100: prior_loss 12.17 task_loss 8.83 \n",
      "step   90/100: prior_loss 11.22 task_loss 8.84 \n",
      "step   91/100: prior_loss 10.33 task_loss 8.84 \n",
      "step   92/100: prior_loss 9.50  task_loss 8.84 \n",
      "step   93/100: prior_loss 8.80  task_loss 8.83 \n",
      "step   94/100: prior_loss 8.21  task_loss 8.83 \n",
      "step   95/100: prior_loss 7.72  task_loss 8.81 \n",
      "step   96/100: prior_loss 7.36  task_loss 8.79 \n",
      "step   97/100: prior_loss 7.09  task_loss 8.76 \n",
      "step   98/100: prior_loss 6.90  task_loss 8.77 \n",
      "step   99/100: prior_loss 6.80  task_loss 8.77 \n",
      "step  100/100: prior_loss 6.75  task_loss 8.76 \n",
      "Elapsed: 58.5 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "gen = Generator(network_pkl, latent_space='z+', device=device)\n",
    "# prior = Prior(gen, device=device, prior_type='cluster', regularize_cluster_weight=1.5, cluster_samples=2000)\n",
    "prior = None\n",
    "blue_target = torch.cat((torch.zeros(2, 512, 512), 255*torch.ones(1, 512, 512)), 0)\n",
    "task = Task(device=device, target=blue_target)\n",
    "projector = Projector(gen, task, prior=prior, device=device)\n",
    "\n",
    "# Optimize projection.\n",
    "start_time = perf_counter()\n",
    "\n",
    "# later TODO mem optimization -> mixed precision, gradient checkpointing, multiGPU \n",
    "projected_w_steps = projector.project(\n",
    "    num_images=12,\n",
    "    num_steps=100,\n",
    ")\n",
    "\n",
    "print (f'Elapsed: {(perf_counter()-start_time):.1f} s')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n",
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n",
      "step    1/100: prior_loss 0.00  task_loss 9.26 \n",
      "step    2/100: prior_loss 0.00  task_loss 9.27 \n",
      "step    3/100: prior_loss 0.00  task_loss 8.56 \n",
      "step    4/100: prior_loss 0.00  task_loss 8.01 \n",
      "step    5/100: prior_loss 0.00  task_loss 7.51 \n",
      "step    6/100: prior_loss 0.00  task_loss 7.08 \n",
      "step    7/100: prior_loss 0.00  task_loss 6.70 \n",
      "step    8/100: prior_loss 0.00  task_loss 6.33 \n",
      "step    9/100: prior_loss 0.00  task_loss 5.96 \n",
      "step   10/100: prior_loss 0.00  task_loss 5.61 \n",
      "step   11/100: prior_loss 0.00  task_loss 5.36 \n",
      "step   12/100: prior_loss 0.00  task_loss 5.17 \n",
      "step   13/100: prior_loss 0.00  task_loss 4.97 \n",
      "step   14/100: prior_loss 0.00  task_loss 4.78 \n",
      "step   15/100: prior_loss 0.00  task_loss 4.56 \n",
      "step   16/100: prior_loss 0.00  task_loss 4.41 \n",
      "step   17/100: prior_loss 0.00  task_loss 4.26 \n",
      "step   18/100: prior_loss 0.00  task_loss 4.14 \n",
      "step   19/100: prior_loss 0.00  task_loss 4.01 \n",
      "step   20/100: prior_loss 0.00  task_loss 3.89 \n",
      "step   21/100: prior_loss 0.00  task_loss 3.77 \n",
      "step   22/100: prior_loss 0.00  task_loss 3.68 \n",
      "step   23/100: prior_loss 0.00  task_loss 3.58 \n",
      "step   24/100: prior_loss 0.00  task_loss 3.48 \n",
      "step   25/100: prior_loss 0.00  task_loss 3.36 \n",
      "step   26/100: prior_loss 0.00  task_loss 3.24 \n",
      "step   27/100: prior_loss 0.00  task_loss 3.14 \n",
      "step   28/100: prior_loss 0.00  task_loss 3.03 \n",
      "step   29/100: prior_loss 0.00  task_loss 2.92 \n",
      "step   30/100: prior_loss 0.00  task_loss 2.80 \n",
      "step   31/100: prior_loss 0.00  task_loss 2.67 \n",
      "step   32/100: prior_loss 0.00  task_loss 2.57 \n",
      "step   33/100: prior_loss 0.00  task_loss 2.48 \n",
      "step   34/100: prior_loss 0.00  task_loss 2.39 \n",
      "step   35/100: prior_loss 0.00  task_loss 2.30 \n",
      "step   36/100: prior_loss 0.00  task_loss 2.22 \n",
      "step   37/100: prior_loss 0.00  task_loss 2.16 \n",
      "step   38/100: prior_loss 0.00  task_loss 2.10 \n",
      "step   39/100: prior_loss 0.00  task_loss 2.04 \n",
      "step   40/100: prior_loss 0.00  task_loss 1.99 \n",
      "step   41/100: prior_loss 0.00  task_loss 1.93 \n",
      "step   42/100: prior_loss 0.00  task_loss 1.87 \n",
      "step   43/100: prior_loss 0.00  task_loss 1.83 \n",
      "step   44/100: prior_loss 0.00  task_loss 1.78 \n",
      "step   45/100: prior_loss 0.00  task_loss 1.73 \n",
      "step   46/100: prior_loss 0.00  task_loss 1.67 \n",
      "step   47/100: prior_loss 0.00  task_loss 1.61 \n",
      "step   48/100: prior_loss 0.00  task_loss 1.55 \n",
      "step   49/100: prior_loss 0.00  task_loss 1.48 \n",
      "step   50/100: prior_loss 0.00  task_loss 1.42 \n",
      "step   51/100: prior_loss 0.00  task_loss 1.38 \n",
      "step   52/100: prior_loss 0.00  task_loss 1.32 \n",
      "step   53/100: prior_loss 0.00  task_loss 1.25 \n",
      "step   54/100: prior_loss 0.00  task_loss 1.20 \n",
      "step   55/100: prior_loss 0.00  task_loss 1.13 \n",
      "step   56/100: prior_loss 0.00  task_loss 1.07 \n",
      "step   57/100: prior_loss 0.00  task_loss 1.03 \n",
      "step   58/100: prior_loss 0.00  task_loss 0.99 \n",
      "step   59/100: prior_loss 0.00  task_loss 0.98 \n",
      "step   60/100: prior_loss 0.00  task_loss 0.96 \n",
      "step   61/100: prior_loss 0.00  task_loss 0.93 \n",
      "step   62/100: prior_loss 0.00  task_loss 0.91 \n",
      "step   63/100: prior_loss 0.00  task_loss 0.89 \n",
      "step   64/100: prior_loss 0.00  task_loss 0.89 \n",
      "step   65/100: prior_loss 0.00  task_loss 0.86 \n",
      "step   66/100: prior_loss 0.00  task_loss 0.84 \n",
      "step   67/100: prior_loss 0.00  task_loss 0.83 \n",
      "step   68/100: prior_loss 0.00  task_loss 0.81 \n",
      "step   69/100: prior_loss 0.00  task_loss 0.79 \n",
      "step   70/100: prior_loss 0.00  task_loss 0.77 \n",
      "step   71/100: prior_loss 0.00  task_loss 0.75 \n",
      "step   72/100: prior_loss 0.00  task_loss 0.73 \n",
      "step   73/100: prior_loss 0.00  task_loss 0.72 \n",
      "step   74/100: prior_loss 0.00  task_loss 0.71 \n",
      "step   75/100: prior_loss 0.00  task_loss 0.69 \n",
      "step   76/100: prior_loss 0.00  task_loss 0.68 \n",
      "step   77/100: prior_loss 0.00  task_loss 0.67 \n",
      "step   78/100: prior_loss 0.00  task_loss 0.66 \n",
      "step   79/100: prior_loss 0.00  task_loss 0.64 \n",
      "step   80/100: prior_loss 0.00  task_loss 0.63 \n",
      "step   81/100: prior_loss 0.00  task_loss 0.62 \n",
      "step   82/100: prior_loss 0.00  task_loss 0.62 \n",
      "step   83/100: prior_loss 0.00  task_loss 0.61 \n",
      "step   84/100: prior_loss 0.00  task_loss 0.60 \n",
      "step   85/100: prior_loss 0.00  task_loss 0.59 \n",
      "step   86/100: prior_loss 0.00  task_loss 0.58 \n",
      "step   87/100: prior_loss 0.00  task_loss 0.58 \n",
      "step   88/100: prior_loss 0.00  task_loss 0.57 \n",
      "step   89/100: prior_loss 0.00  task_loss 0.57 \n",
      "step   90/100: prior_loss 0.00  task_loss 0.56 \n",
      "step   91/100: prior_loss 0.00  task_loss 0.56 \n",
      "step   92/100: prior_loss 0.00  task_loss 0.56 \n",
      "step   93/100: prior_loss 0.00  task_loss 0.55 \n",
      "step   94/100: prior_loss 0.00  task_loss 0.55 \n",
      "step   95/100: prior_loss 0.00  task_loss 0.55 \n",
      "step   96/100: prior_loss 0.00  task_loss 0.55 \n",
      "step   97/100: prior_loss 0.00  task_loss 0.54 \n",
      "step   98/100: prior_loss 0.00  task_loss 0.54 \n",
      "step   99/100: prior_loss 0.00  task_loss 0.54 \n",
      "step  100/100: prior_loss 0.00  task_loss 0.54 \n",
      "Elapsed: 62.0 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Render debug output: optional video and projected image and W vector.\n",
    "num_rows = 3\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "with torch.no_grad():\n",
    "    if save_video:\n",
    "        video = imageio.get_writer(f'{outdir}/test.mp4', mode='I', fps=10, codec='libx264', bitrate='1M')\n",
    "        print (f'Saving optimization progress video \"{outdir}/test.mp4\"')\n",
    "        for projected_w in projected_w_steps:\n",
    "            synth_image = projector.gen.latent_to_image(projected_w)\n",
    "            synth_image = (synth_image + 1) * (255/2)\n",
    "            synth_image = synth_image.permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8).cpu().numpy()\n",
    "            grid_image = einops.rearrange(synth_image, \"(n1 n2) h w c-> (n1 h) (n2 w) c\", n1=num_rows)\n",
    "            video.append_data(grid_image)\n",
    "            # video.append_data(np.concatenate([target_uint8, synth_image], axis=1))\n",
    "        video.close()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Save final projected frame and W vector.\n",
    "target_pil.save(f'{outdir}/target.png')\n",
    "projected_w = projected_w_steps[-1]\n",
    "synth_image = G.synthesis(projected_w.unsqueeze(0), noise_mode='none')\n",
    "synth_image = (synth_image + 1) * (255/2)\n",
    "synth_image = synth_image.permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n",
    "PIL.Image.fromarray(synth_image, 'RGB').save(f'{outdir}/projblue.png')\n",
    "np.savez(f'{outdir}/projected_wblue.npz', w=projected_w.unsqueeze(0).cpu().numpy())"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}