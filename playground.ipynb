{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "!pip install imageio\n",
    "!pip install imageio-ffmpeg\n",
    "!wget https://people.eecs.berkeley.edu/~efros/img/Efros__photo_Peter_Badge_crop.jpg\n",
    "!ls "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: imageio in /home/oleksiiv/anaconda3/envs/ganenv4/lib/python3.9/site-packages (2.9.0)\n",
      "Requirement already satisfied: numpy in /home/oleksiiv/anaconda3/envs/ganenv4/lib/python3.9/site-packages (from imageio) (1.21.2)\n",
      "Requirement already satisfied: pillow in /home/oleksiiv/anaconda3/envs/ganenv4/lib/python3.9/site-packages (from imageio) (8.3.1)\n",
      "Requirement already satisfied: imageio-ffmpeg in /home/oleksiiv/anaconda3/envs/ganenv4/lib/python3.9/site-packages (0.4.5)\n",
      "--2021-08-30 22:37:46--  https://people.eecs.berkeley.edu/~efros/img/Efros__photo_Peter_Badge_crop.jpg\n",
      "Resolving people.eecs.berkeley.edu (people.eecs.berkeley.edu)... 128.32.244.190\n",
      "Connecting to people.eecs.berkeley.edu (people.eecs.berkeley.edu)|128.32.244.190|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 456031 (445K) [image/jpeg]\n",
      "Saving to: ‘Efros__photo_Peter_Badge_crop.jpg’\n",
      "\n",
      "Efros__photo_Peter_ 100%[===================>] 445.34K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2021-08-30 22:37:47 (4.34 MB/s) - ‘Efros__photo_Peter_Badge_crop.jpg’ saved [456031/456031]\n",
      "\n",
      "calc_metrics.py\n",
      "dataset_tool.py\n",
      "dnnlib\n",
      "Dockerfile\n",
      "docker_run.sh\n",
      "docs\n",
      "e6MuEwjO9Xm9aILQc_UJg3pneDuV87-xIws_FgeiSIfgd9i510kbWwrvxgGgdroMqPyWQotseeQJX2vCA8XfU1tGzTN8bw\n",
      "efros.jpg\n",
      "Efros__photo_Peter_Badge_crop.jpg\n",
      "environment.yml\n",
      "generate.py\n",
      "legacy.py\n",
      "LICENSE.txt\n",
      "malik.jpg\n",
      "malik.jpg.1\n",
      "metrics\n",
      "out\n",
      "playground.ipynb\n",
      "projector.py\n",
      "__pycache__\n",
      "README.md\n",
      "style_mixing.py\n",
      "test.ipynb\n",
      "torch_utils\n",
      "training\n",
      "train.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "!mv Efros__photo_Peter_Badge_crop.jpg efros.jpg"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "calc_metrics.py\n",
      "dataset_tool.py\n",
      "dnnlib\n",
      "Dockerfile\n",
      "docker_run.sh\n",
      "docs\n",
      "e6MuEwjO9Xm9aILQc_UJg3pneDuV87-xIws_FgeiSIfgd9i510kbWwrvxgGgdroMqPyWQotseeQJX2vCA8XfU1tGzTN8bw\n",
      "efros.jpg\n",
      "environment.yml\n",
      "generate.py\n",
      "legacy.py\n",
      "LICENSE.txt\n",
      "malik.jpg\n",
      "malik.jpg.1\n",
      "metrics\n",
      "out\n",
      "playground.ipynb\n",
      "projector.py\n",
      "__pycache__\n",
      "README.md\n",
      "style_mixing.py\n",
      "test.ipynb\n",
      "torch_utils\n",
      "training\n",
      "train.py\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import copy\n",
    "import os\n",
    "from time import perf_counter\n",
    "import click\n",
    "import imageio\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import dnnlib\n",
    "import legacy"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "source": [
    "def project(\n",
    "    G,\n",
    "    target: torch.Tensor, # [C,H,W] and dynamic range [0,255], W & H must match G output resolution\n",
    "    *,\n",
    "    num_steps                  = 1000,\n",
    "    w_avg_samples              = 10000,\n",
    "    initial_learning_rate      = 0.1,\n",
    "    initial_noise_factor       = 0.05,\n",
    "    lr_rampdown_length         = 0.25,\n",
    "    lr_rampup_length           = 0.05,\n",
    "    noise_ramp_length          = 0.75,\n",
    "    regularize_noise_weight    = 1e5,\n",
    "    verbose                    = False,\n",
    "    device: torch.device\n",
    "):\n",
    "    target = (torch.cat((torch.zeros(2, 1024, 1024), 255*torch.ones(1, 1024, 1024)), 0)).to(device)\n",
    "    print(target.shape,(G.img_channels, G.img_resolution, G.img_resolution))\n",
    "    assert target.shape == (G.img_channels, G.img_resolution, G.img_resolution)\n",
    "\n",
    "    def logprint(*args):\n",
    "        if verbose:\n",
    "            print(*args)\n",
    "\n",
    "    G = copy.deepcopy(G).eval().requires_grad_(False).to(device) # type: ignore\n",
    "\n",
    "    # Compute w stats.\n",
    "    logprint(f'Computing W midpoint and stddev using {w_avg_samples} samples...')\n",
    "    z_samples = np.random.RandomState(123).randn(w_avg_samples, G.z_dim)\n",
    "    w_samples = G.mapping(torch.from_numpy(z_samples).to(device), None)  # [N, L, C]\n",
    "    w_samples = w_samples[:, :1, :].cpu().numpy().astype(np.float32)       # [N, 1, C]\n",
    "    w_avg = np.mean(w_samples, axis=0, keepdims=True)      # [1, 1, C]\n",
    "    w_std = (np.sum((w_samples - w_avg) ** 2) / w_avg_samples) ** 0.5\n",
    "\n",
    "    # Setup noise inputs.\n",
    "    noise_bufs = { name: buf for (name, buf) in G.synthesis.named_buffers() if 'noise_const' in name }\n",
    "\n",
    "    # Load VGG16 feature detector.\n",
    "    url = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metrics/vgg16.pt'\n",
    "    with dnnlib.util.open_url(url) as f:\n",
    "        vgg16 = torch.jit.load(f).eval().to(device)\n",
    "\n",
    "    # Features for target image.\n",
    "    target_images = target.unsqueeze(0).to(device).to(torch.float32)\n",
    "    if target_images.shape[2] > 256:\n",
    "        target_images = F.interpolate(target_images, size=(256, 256), mode='area')\n",
    "    target_features = vgg16(target_images, resize_images=False, return_lpips=True)\n",
    "\n",
    "    w_opt = torch.tensor(w_avg, dtype=torch.float32, device=device, requires_grad=True) # pylint: disable=not-callable\n",
    "    w_out = torch.zeros([num_steps] + list(w_opt.shape[1:]), dtype=torch.float32, device=device)\n",
    "    optimizer = torch.optim.Adam([w_opt] + list(noise_bufs.values()), betas=(0.9, 0.999), lr=initial_learning_rate)\n",
    "\n",
    "    # Init noise.\n",
    "    for buf in noise_bufs.values():\n",
    "        buf[:] = torch.randn_like(buf)\n",
    "        buf.requires_grad = True\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        # Learning rate schedule.\n",
    "        t = step / num_steps\n",
    "        w_noise_scale = w_std * initial_noise_factor * max(0.0, 1.0 - t / noise_ramp_length) ** 2\n",
    "        lr_ramp = min(1.0, (1.0 - t) / lr_rampdown_length)\n",
    "        lr_ramp = 0.5 - 0.5 * np.cos(lr_ramp * np.pi)\n",
    "        lr_ramp = lr_ramp * min(1.0, t / lr_rampup_length)\n",
    "        lr = initial_learning_rate * lr_ramp\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "        # Synth images from opt_w.\n",
    "        w_noise = torch.randn_like(w_opt) * w_noise_scale\n",
    "        ws = (w_opt + w_noise).repeat([1, G.mapping.num_ws, 1])\n",
    "        synth_images = G.synthesis(ws, noise_mode='const')\n",
    "\n",
    "        # Downsample image to 256x256 if it's larger than that. VGG was built for 224x224 images.\n",
    "        synth_images = (synth_images + 1) * (255/2)\n",
    "        if synth_images.shape[2] > 256:\n",
    "            synth_images = F.interpolate(synth_images, size=(256, 256), mode='area')\n",
    "\n",
    "        # Features for synth images.\n",
    "        synth_features = vgg16(synth_images, resize_images=False, return_lpips=True)\n",
    "        dist = (target_features - synth_features).square().sum()\n",
    "\n",
    "        # Noise regularization.\n",
    "        reg_loss = 0.0\n",
    "        for v in noise_bufs.values():\n",
    "            noise = v[None,None,:,:] # must be [1,1,H,W] for F.avg_pool2d()\n",
    "            while True:\n",
    "                reg_loss += (noise*torch.roll(noise, shifts=1, dims=3)).mean()**2\n",
    "                reg_loss += (noise*torch.roll(noise, shifts=1, dims=2)).mean()**2\n",
    "                if noise.shape[2] <= 8:\n",
    "                    break\n",
    "                noise = F.avg_pool2d(noise, kernel_size=2)\n",
    "        loss = dist + reg_loss * regularize_noise_weight\n",
    "\n",
    "        # Step\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        logprint(f'step {step+1:>4d}/{num_steps}: dist {dist:<4.2f} loss {float(loss):<5.2f}')\n",
    "\n",
    "        # Save projected W for each optimization step.\n",
    "        w_out[step] = w_opt.detach()[0]\n",
    "\n",
    "        # Normalize noise.\n",
    "        with torch.no_grad():\n",
    "            for buf in noise_bufs.values():\n",
    "                buf -= buf.mean()\n",
    "                buf *= buf.square().mean().rsqrt()\n",
    "\n",
    "    return w_out.repeat([1, G.mapping.num_ws, 1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "def project_blue(\n",
    "    G,\n",
    "    target: torch.Tensor, # [C,H,W] and dynamic range [0,255], W & H must match G output resolution\n",
    "    *,\n",
    "    num_steps                  = 1000,\n",
    "    w_avg_samples              = 10000,\n",
    "    initial_learning_rate      = 0.1,\n",
    "    initial_noise_factor       = 0.05,\n",
    "    lr_rampdown_length         = 0.25,\n",
    "    lr_rampup_length           = 0.05,\n",
    "    noise_ramp_length          = 0.75,\n",
    "    regularize_noise_weight    = 1e5,\n",
    "    verbose                    = False,\n",
    "    device: torch.device\n",
    "):\n",
    "    assert target.shape == (G.img_channels, G.img_resolution, G.img_resolution)\n",
    "\n",
    "    def logprint(*args):\n",
    "        if verbose:\n",
    "            print(*args)\n",
    "\n",
    "    G = copy.deepcopy(G).eval().requires_grad_(False).to(device) # type: ignore\n",
    "\n",
    "    # Compute w stats.\n",
    "    logprint(f'Computing W midpoint and stddev using {w_avg_samples} samples...')\n",
    "    z_samples = np.random.RandomState(123).randn(w_avg_samples, G.z_dim)\n",
    "    w_samples = G.mapping(torch.from_numpy(z_samples).to(device), None)  # [N, L, C]\n",
    "    w_samples = w_samples[:, :1, :].cpu().numpy().astype(np.float32)       # [N, 1, C]\n",
    "    w_avg = np.mean(w_samples, axis=0, keepdims=True)      # [1, 1, C]\n",
    "    w_std = (np.sum((w_samples - w_avg) ** 2) / w_avg_samples) ** 0.5\n",
    "\n",
    "    # Setup noise inputs.\n",
    "    noise_bufs = { name: buf for (name, buf) in G.synthesis.named_buffers() if 'noise_const' in name }\n",
    "\n",
    "    # Load VGG16 feature detector.\n",
    "    # url = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metrics/vgg16.pt'\n",
    "    # with dnnlib.util.open_url(url) as f:\n",
    "    #     vgg16 = torch.jit.load(f).eval().to(device)\n",
    "\n",
    "    # Features for target image.\n",
    "    target_images = target.unsqueeze(0).to(device).to(torch.float32)\n",
    "    if target_images.shape[2] > 256:\n",
    "        target_images = F.interpolate(target_images, size=(256, 256), mode='area')\n",
    "    # target_features = vgg16(target_images, resize_images=False, return_lpips=True)\n",
    "\n",
    "    w_opt = torch.tensor(w_avg, dtype=torch.float32, device=device, requires_grad=True) # pylint: disable=not-callable\n",
    "    w_out = torch.zeros([num_steps] + list(w_opt.shape[1:]), dtype=torch.float32, device=device)\n",
    "    # optimizer = torch.optim.Adam([w_opt] + list(noise_bufs.values()), betas=(0.9, 0.999), lr=initial_learning_rate)\n",
    "    optimizer = torch.optim.Adam([w_opt], betas=(0.9, 0.999), lr=initial_learning_rate)\n",
    "\n",
    "    # Init noise.\n",
    "    for buf in noise_bufs.values():\n",
    "        buf[:] = torch.randn_like(buf)\n",
    "        buf.requires_grad = True\n",
    "\n",
    "    for step in range(num_steps):\n",
    "        # Learning rate schedule.\n",
    "        t = step / num_steps\n",
    "        w_noise_scale = w_std * initial_noise_factor * max(0.0, 1.0 - t / noise_ramp_length) ** 2\n",
    "        \n",
    "        lr_ramp = min(1.0, (1.0 - t) / lr_rampdown_length)\n",
    "        lr_ramp = 0.5 - 0.5 * np.cos(lr_ramp * np.pi)\n",
    "        lr_ramp = lr_ramp * min(1.0, t / lr_rampup_length)\n",
    "        lr = initial_learning_rate * lr_ramp\n",
    "        print(\"\\t\", lr)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "\n",
    "        # Synth images from opt_w.\n",
    "        w_noise = torch.randn_like(w_opt) * w_noise_scale\n",
    "        ws = (w_opt + w_noise).repeat([1, G.mapping.num_ws, 1])\n",
    "        synth_images = G.synthesis(ws, noise_mode='const')\n",
    "\n",
    "        # Downsample image to 256x256 if it's larger than that. VGG was built for 224x224 images.\n",
    "        synth_images = (synth_images + 1) * (255/2)\n",
    "        if synth_images.shape[2] > 256:\n",
    "            synth_images = F.interpolate(synth_images, size=(256, 256), mode='area')\n",
    "\n",
    "        # # Features for synth images.\n",
    "        # synth_features = vgg16(synth_images, resize_images=False, return_lpips=True)\n",
    "        # print(target_images.size())\n",
    "        # print(target_images.max())\n",
    "        # print(synth_images.size())\n",
    "        # print(synth_images.max())\n",
    "        # print(synth_images.mean())\n",
    "        dist = (target_images - synth_images).square().sum()\n",
    "\n",
    "        # Noise regularization.\n",
    "        # reg_loss = 0.0\n",
    "        # for v in noise_bufs.values():\n",
    "        #     noise = v[None,None,:,:] # must be [1,1,H,W] for F.avg_pool2d()\n",
    "        #     while True:\n",
    "        #         reg_loss += (noise*torch.roll(noise, shifts=1, dims=3)).mean()**2\n",
    "        #         reg_loss += (noise*torch.roll(noise, shifts=1, dims=2)).mean()**2\n",
    "        #         if noise.shape[2] <= 8:\n",
    "        #             break\n",
    "        #         noise = F.avg_pool2d(noise, kernel_size=2)\n",
    "        loss = dist #+ reg_loss * regularize_noise_weight\n",
    "\n",
    "        # Step\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        logprint(f'step {step+1:>4d}/{num_steps}: dist {dist:<4.2f} loss {float(loss):<5.2f}')\n",
    "\n",
    "        # Save projected W for each optimization step.\n",
    "        w_out[step] = w_opt.detach()[0]\n",
    "\n",
    "        # Normalize noise.\n",
    "        with torch.no_grad():\n",
    "            for buf in noise_bufs.values():\n",
    "                buf -= buf.mean()\n",
    "                buf *= buf.square().mean().rsqrt()\n",
    "\n",
    "    return w_out.repeat([1, G.mapping.num_ws, 1])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "network_pkl = \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\"\n",
    "target_fname = \"efros.jpg\"\n",
    "outdir = \"out\"\n",
    "save_video = True\n",
    "seed = 202\n",
    "num_steps = 200"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5fc8129c70>"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "# Load networks.\n",
    "print('Loading networks from \"%s\"...' % network_pkl)\n",
    "device = torch.device('cuda')\n",
    "with dnnlib.util.open_url(network_pkl) as fp:\n",
    "    G = legacy.load_network_pkl(fp)['G_ema'].requires_grad_(False).to(device) # type: ignore"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading networks from \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\"...\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "# Load target image.\n",
    "target_pil = PIL.Image.open(target_fname).convert('RGB')\n",
    "w, h = target_pil.size\n",
    "s = min(w, h)\n",
    "target_pil = target_pil.crop(((w - s) // 2, (h - s) // 2, (w + s) // 2, (h + s) // 2))\n",
    "target_pil = target_pil.resize((G.img_resolution, G.img_resolution), PIL.Image.LANCZOS)\n",
    "target_uint8 = np.array(target_pil, dtype=np.uint8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "# Optimize projection.\n",
    "start_time = perf_counter()\n",
    "projected_w_steps = project_blue(\n",
    "    G,\n",
    "    target=torch.cat((torch.zeros(2, 1024, 1024), 255*torch.ones(1, 1024, 1024)), 0), # pylint: disable=not-callable\n",
    "    num_steps=num_steps,\n",
    "    device=device,\n",
    "    verbose=True,\n",
    "    # initial_learning_rate=0\n",
    ")\n",
    "\n",
    "# projected_w_steps = project(\n",
    "#     G,\n",
    "#     target=torch.tensor(target_uint8.transpose([2, 0, 1]), device=device), # pylint: disable=not-callable\n",
    "#     num_steps=num_steps,\n",
    "#     device=device,\n",
    "#     verbose=True,\n",
    "#     # initial_learning_rate=0\n",
    "# )\n",
    "print (f'Elapsed: {(perf_counter()-start_time):.1f} s')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Computing W midpoint and stddev using 10000 samples...\n",
      "\t 0.0\n",
      "step    1/200: dist 3466543104.00 loss 3466543104.00\n",
      "\t 0.01\n",
      "step    2/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.02\n",
      "step    3/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.03\n",
      "step    4/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.04\n",
      "step    5/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.05\n",
      "step    6/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.06\n",
      "step    7/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.07\n",
      "step    8/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.08\n",
      "step    9/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.09\n",
      "step   10/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   11/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   12/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   13/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   14/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   15/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   16/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   17/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   18/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   19/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   20/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   21/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   22/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   23/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   24/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   25/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   26/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   27/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   28/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   29/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   30/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   31/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   32/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   33/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   34/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   35/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   36/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   37/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   38/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   39/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   40/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   41/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   42/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   43/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   44/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   45/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   46/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   47/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   48/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   49/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   50/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   51/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   52/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   53/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   54/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   55/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   56/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   57/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   58/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   59/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   60/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   61/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   62/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   63/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   64/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   65/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   66/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   67/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   68/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   69/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   70/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   71/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   72/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   73/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   74/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   75/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   76/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   77/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   78/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   79/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   80/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   81/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   82/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   83/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   84/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   85/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   86/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   87/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   88/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   89/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   90/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   91/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   92/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   93/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   94/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   95/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   96/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   97/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   98/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step   99/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  100/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  101/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  102/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  103/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  104/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  105/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  106/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  107/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  108/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  109/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  110/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  111/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  112/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  113/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  114/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  115/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  116/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  117/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  118/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  119/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  120/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  121/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  122/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  123/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  124/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  125/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  126/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  127/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  128/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  129/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  130/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  131/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  132/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  133/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  134/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  135/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  136/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  137/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  138/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  139/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  140/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  141/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  142/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  143/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  144/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  145/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  146/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  147/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  148/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  149/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  150/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.1\n",
      "step  151/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.09990133642141358\n",
      "step  152/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.0996057350657239\n",
      "step  153/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.09911436253643444\n",
      "step  154/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.09842915805643156\n",
      "step  155/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.09755282581475767\n",
      "step  156/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.09648882429441256\n",
      "step  157/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.09524135262330097\n",
      "step  158/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.09381533400219318\n",
      "step  159/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.09221639627510075\n",
      "step  160/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.09045084971874735\n",
      "step  161/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.08852566213878944\n",
      "step  162/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.08644843137107056\n",
      "step  163/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.08422735529643446\n",
      "step  164/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.08187119948743452\n",
      "step  165/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.07938926261462367\n",
      "step  166/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.07679133974894986\n",
      "step  167/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.07408768370508577\n",
      "step  168/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.07128896457825364\n",
      "step  169/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.06840622763423392\n",
      "step  170/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.06545084971874737\n",
      "step  171/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.06243449435824275\n",
      "step  172/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.05936906572928624\n",
      "step  173/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.056266661678215216\n",
      "step  174/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.05313952597646568\n",
      "step  175/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.049999999999999996\n",
      "step  176/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.046860474023534326\n",
      "step  177/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.043733338321784776\n",
      "step  178/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.04063093427071376\n",
      "step  179/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.03756550564175726\n",
      "step  180/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.03454915028125262\n",
      "step  181/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.03159377236576608\n",
      "step  182/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.028711035421746346\n",
      "step  183/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.02591231629491422\n",
      "step  184/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.023208660251050145\n",
      "step  185/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.02061073738537632\n",
      "step  186/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.01812880051256549\n",
      "step  187/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.01577264470356554\n",
      "step  188/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.013551568628929445\n",
      "step  189/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.01147433786121056\n",
      "step  190/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.009549150281252645\n",
      "step  191/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.007783603724899258\n",
      "step  192/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.006184665997806833\n",
      "step  193/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.004758647376699033\n",
      "step  194/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.0035111757055874327\n",
      "step  195/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.0024471741852423235\n",
      "step  196/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.0015708419435684464\n",
      "step  197/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.0008856374635655695\n",
      "step  198/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 0.0003942649342761118\n",
      "step  199/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "\t 9.866357858642206e-05\n",
      "step  200/200: dist 15651530841522176.00 loss 15651530841522176.00\n",
      "Elapsed: 16.4 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "# Render debug output: optional video and projected image and W vector.\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "if save_video:\n",
    "    video = imageio.get_writer(f'{outdir}/projblue.mp4', mode='I', fps=10, codec='libx264', bitrate='16M')\n",
    "    print (f'Saving optimization progress video \"{outdir}/proj.mp4\"')\n",
    "    for projected_w in projected_w_steps:\n",
    "        synth_image = G.synthesis(projected_w.unsqueeze(0), noise_mode='const')\n",
    "        synth_image = (synth_image + 1) * (255/2)\n",
    "        synth_image = synth_image.permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n",
    "        video.append_data(np.concatenate([target_uint8, synth_image], axis=1))\n",
    "    video.close()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving optimization progress video \"out/proj.mp4\"\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "source": [
    "# Save final projected frame and W vector.\n",
    "target_pil.save(f'{outdir}/target.png')\n",
    "projected_w = projected_w_steps[-1]\n",
    "synth_image = G.synthesis(projected_w.unsqueeze(0), noise_mode='const')\n",
    "synth_image = (synth_image + 1) * (255/2)\n",
    "synth_image = synth_image.permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n",
    "PIL.Image.fromarray(synth_image, 'RGB').save(f'{outdir}/projblue.png')\n",
    "np.savez(f'{outdir}/projected_wblue.npz', w=projected_w.unsqueeze(0).cpu().numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(\"Done\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Done\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"out/projblue.mp4\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<IPython.core.display.Video object>"
      ],
      "text/html": [
       "<video src=\"out/projblue.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}